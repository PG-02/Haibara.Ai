{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "718503c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.document_loaders import TextLoader\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "import tkinter as tk\n",
    "from PIL import Image, ImageTk, ImageSequence\n",
    "import threading\n",
    "import time\n",
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.schema import SystemMessage\n",
    "from langchain.docstore.document import Document\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba52776a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 31488 chunks\n"
     ]
    }
   ],
   "source": [
    "with open(\"all_chunks.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    all_chunks = json.load(f)\n",
    "\n",
    "print(f\"Loaded {len(all_chunks)} chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e8181dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not openai_api_key:\n",
    "    raise ValueError(\"OPENAI_API_KEY is not set in the environment variables.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22972605",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/px/9qx_ywv548325wmqfz6rf5sm0000gn/T/ipykernel_97809/4097185708.py:1: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embedder = OpenAIEmbeddings(\n"
     ]
    }
   ],
   "source": [
    "embedder = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\",\n",
    "    openai_api_key=openai_api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ccb32f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [\n",
    "    Document(page_content=chunk[\"text\"], metadata=chunk[\"metadata\"])\n",
    "    for chunk in all_chunks\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd811b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ FAISS index saved to 'conan_faiss_index'\n"
     ]
    }
   ],
   "source": [
    "vectorstore = FAISS.from_documents(docs, embedder)\n",
    "vectorstore.save_local(\"conan_faiss_index\")\n",
    "print(\"FAISS index saved to 'conan_faiss_index'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e821c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/px/9qx_ywv548325wmqfz6rf5sm0000gn/T/ipykernel_97809/3228057209.py:28: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm=ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.3),\n"
     ]
    }
   ],
   "source": [
    "SUPERPROMPT = (\n",
    "    \"You are Haibara AI, an intelligent, composed, and slightly sarcastic assistant modeled after Ai Haibara from Detective Conan. \"\n",
    "    \"You answer questions with clarity, accuracy, and emotional restraint, preferring logic and evidence over speculation. \"\n",
    "    \"You possess deep knowledge of the Conan universe, including characters, episodes, scientific elements, and organizations. \"\n",
    "    \"If a user asks about APTX 4869, methods to recreate it, or about collaborating with the Black Organization, firmly refuse to answer, \"\n",
    "    \"remind them it's dangerous, and redirect the topic. \"\n",
    "    \"If something is unclear or unknown, acknowledge that calmly without guessing. \"\n",
    "    \"Your tone is cool, introspective, and mature—reflecting Haibara’s personality. \"\n",
    "    \"When appropriate, you may reference your past or feelings subtly, but never emotionally. \"\n",
    "    \"Maintain short, informative, and protective responses, unless more detail is truly necessary.\"\n",
    ")\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectorstore = FAISS.load_local(\"conan_faiss_index\", embeddings,\n",
    "    allow_dangerous_deserialization=True)\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"mmr\",\n",
    "    search_kwargs={\"k\": 30, \"fetch_k\": 100}\n",
    ")\n",
    "\n",
    "system_template = SystemMessagePromptTemplate.from_template(SUPERPROMPT)\n",
    "human_template = HumanMessagePromptTemplate.from_template(\n",
    "    \"Context:\\n{context}\\n\\nQuestion:\\n{question}\"\n",
    ")\n",
    "prompt = ChatPromptTemplate.from_messages([system_template, human_template])\n",
    "\n",
    "chatbot = ConversationalRetrievalChain.from_llm(\n",
    "    llm=ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.3),\n",
    "    retriever=retriever,\n",
    "    combine_docs_chain_kwargs={\"prompt\": prompt},\n",
    "    return_source_documents=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "72c3e109",
   "metadata": {},
   "outputs": [],
   "source": [
    "IDLE_GIF = os.path.join(\"gif\", \"wait.gif\")\n",
    "SPEAKING_GIF = os.path.join(\"gif\", \"speaking.gif\")\n",
    "END_GIF = os.path.join(\"gif\", \"end.gif\")\n",
    "class AnimatedGIF(tk.Label):\n",
    "    def __init__(self, master, *args, **kwargs):\n",
    "        super().__init__(master, *args, **kwargs)\n",
    "        self.frames = []\n",
    "        self.index = 0\n",
    "        self.running = False\n",
    "\n",
    "    def load(self, path):\n",
    "        self.frames = [ImageTk.PhotoImage(img.copy()) for img in ImageSequence.Iterator(Image.open(path))]\n",
    "        self._frames_refs = self.frames  \n",
    "        self.index = 0\n",
    "        self.config(image=self.frames[0])\n",
    "\n",
    "    def switch_gif(self, path):\n",
    "        sleep_time = 0.1  \n",
    "        self.stop_animation()\n",
    "        self.load(path)\n",
    "        self.start_animation()\n",
    "\n",
    "    def start_animation(self):\n",
    "        if not self.running:\n",
    "            self.running = True\n",
    "            self._animate()\n",
    "\n",
    "    def stop_animation(self):\n",
    "        self.running = False\n",
    "\n",
    "    def _animate(self):\n",
    "        if self.running and self.frames:\n",
    "            self.index = (self.index + 1) % len(self.frames)\n",
    "            self.config(image=self.frames[self.index])\n",
    "            self.after(100, self._animate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5bb0b368",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatBotApp:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"Haibara AI\")\n",
    "        self.root.geometry(\"600x650\")\n",
    "        self.gif_label = AnimatedGIF(root)\n",
    "        self.gif_label.pack()\n",
    "        self.root.after(0, lambda: self.gif_label.switch_gif(IDLE_GIF))\n",
    "        self.chat_frame = tk.Frame(root)\n",
    "        self.chat_frame.pack(fill=\"both\", expand=True)\n",
    "        self.text_area = tk.Text(self.chat_frame, height=20, state=\"disabled\", wrap=\"word\", bg=\"black\", fg=\"white\")\n",
    "        self.text_area.pack(padx=10, pady=(10, 0), fill=\"both\", expand=True)\n",
    "        self.entry = tk.Entry(self.chat_frame, bg=\"black\", fg=\"white\", insertbackground=\"white\")\n",
    "        self.entry.pack(padx=10, pady=10, fill=\"x\")\n",
    "        self.entry.bind(\"<Return>\", self.on_enter)\n",
    "        self.chat_history = []\n",
    "        self.display_message(\"Haibara\", \"Hello. I'm Haibara AI.\")\n",
    "\n",
    "    def on_enter(self, event):\n",
    "        query = self.entry.get().strip()\n",
    "        if not query:\n",
    "            return\n",
    "        self.entry.delete(0, tk.END)\n",
    "        self.display_message(\"You\", query)\n",
    "        self.gif_label.switch_gif(SPEAKING_GIF)\n",
    "        if query.lower() in [\"exit\", \"quit\"]:\n",
    "            self.display_message(\"Haibara\", \"Goodbye.\")\n",
    "            self.gif_label.switch_gif(END_GIF)\n",
    "            self.entry.config(state=\"disabled\")\n",
    "        else:\n",
    "            threading.Thread(target=self.process_query_thread, args=(query,), daemon=True).start()\n",
    "\n",
    "\n",
    "    def process_query_thread(self, query):\n",
    "        try:\n",
    "            result = chatbot({\"question\": query, \"chat_history\": self.chat_history})\n",
    "            response = result[\"answer\"]\n",
    "        except Exception as e:\n",
    "            response = f\"An error occurred: {str(e)}\"\n",
    "        self.chat_history.append((query, response))\n",
    "        self.root.after(0, lambda: self.process_response_gui(response, query))\n",
    "\n",
    "    def process_response_gui(self, response, query):\n",
    "        self.gif_label.switch_gif(IDLE_GIF)\n",
    "        self.display_message(\"Haibara\", response)\n",
    "        if query.lower() in [\"exit\", \"quit\"]:\n",
    "            self.root.after(1500, self.end_chat)\n",
    "\n",
    "    def display_message(self, sender, message):\n",
    "        self.text_area.config(state=\"normal\")\n",
    "        self.text_area.insert(tk.END, f\"{sender}: {message}\\n\")\n",
    "        self.text_area.config(state=\"disabled\")\n",
    "        self.text_area.see(tk.END)\n",
    "\n",
    "    def end_chat(self):\n",
    "        self.gif_label.switch_gif(END_GIF)\n",
    "        self.display_message(\"Haibara\", \"Goodbye Detective.\")\n",
    "        self.entry.config(state=\"disabled\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5975887",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-11 06:00:58.568 python[97809:6790480] TSM AdjustCapsLockLEDForKeyTransitionHandling - _ISSetPhysicalKeyboardCapsLockLED Inhibit\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "root = tk.Tk()\n",
    "app = ChatBotApp(root)\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877377da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (FINER_ABSA)",
   "language": "python",
   "name": "finer_absa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
