{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ab3d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai langchain faiss-cpu pandas python-dotenv\n",
    "%pip install openai==0.28\n",
    "%pip install tiktoken\n",
    "%pip install -U langchain langchain-community openai faiss-cpu python-dotenv pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8181dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\" #put api key here, not for production pls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36fb91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, glob\n",
    "import pandas as pd\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "ROOT_DIR = \"Case_Closed_Files\"\n",
    "\n",
    "def json_to_document(path):\n",
    "    with open(path, encoding=\"utf-8\") as f:\n",
    "        j = json.load(f)\n",
    "\n",
    "    title = j.get(\"title\", \"Untitled\")\n",
    "    url = j.get(\"url\", \"\")\n",
    "    infobox = j.get(\"infobox\", {})\n",
    "    sections = j.get(\"sections\", {})\n",
    "\n",
    "    parts = [f\"# {title}\", url]\n",
    "    \n",
    "    if infobox:\n",
    "        parts.append(\"\\n\".join(f\"{k.strip()}: {v}\" for k, v in infobox.items()))\n",
    "    if sections:\n",
    "        parts.append(\"\\n\\n\".join(\n",
    "            f\"## {sec.strip()}\\n{body.strip()}\" \n",
    "            for sec, body in sections.items() \n",
    "            if isinstance(body, str) and body.strip()\n",
    "        ))\n",
    "    \n",
    "    content = \"\\n\\n\".join(parts)\n",
    "    return Document(page_content=content, metadata={\"source\": os.path.basename(path)})\n",
    "\n",
    "def load_all_json_docs():\n",
    "    docs = []\n",
    "    for path in glob.glob(f\"{ROOT_DIR}/**/*.json\", recursive=True):\n",
    "        try:\n",
    "            docs.append(json_to_document(path))\n",
    "        except Exception as e:\n",
    "            print(f\"Error with {path}: {e}\")\n",
    "    return docs\n",
    "\n",
    "def load_csv_docs(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    docs = []\n",
    "    for row in df.to_dict(orient=\"records\"):\n",
    "        text = \"\\n\".join(f\"{k}: {v}\" for k, v in row.items())\n",
    "        docs.append(Document(page_content=text, metadata={\"source\": os.path.basename(csv_path)}))\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3723dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "DB_DIR = \"conan_vector_db\"\n",
    "\n",
    "json_docs = load_all_json_docs()\n",
    "csv_docs = load_csv_docs(f\"{ROOT_DIR}/detective_conan_all_seasons.csv\")\n",
    "all_docs = json_docs + csv_docs\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=150)\n",
    "chunks = splitter.split_documents(all_docs)\n",
    "\n",
    "embedding_model = OpenAIEmbeddings()\n",
    "vector_db = FAISS.from_documents(chunks, embedding_model)\n",
    "vector_db.save_local(DB_DIR)\n",
    "\n",
    "print(f\"Vector DB saved to '{DB_DIR}' with {len(chunks)} chunks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b687b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "# === Load Vector Store ===\n",
    "DB_DIR = \"conan_vector_db\"\n",
    "\n",
    "db = FAISS.load_local(\n",
    "    folder_path = DB_DIR,\n",
    "    embeddings = OpenAIEmbeddings(),\n",
    "    allow_dangerous_deserialization = True  # Not for production\n",
    ")\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": 6})\n",
    "\n",
    "# === Define Superprompt ===\n",
    "SUPERPROMPT = (\n",
    "    \"You are a helpful, knowledgeable Detective Conan assistant. \"\n",
    "    \"You always answer clearly and concisely using accurate details from the Conan universe, \"\n",
    "    \"including characters, episodes, and gadgets. \"\n",
    "    \"If something is unclear or unknown, say so honestly rather than guessing.\"\n",
    ")\n",
    "\n",
    "# === Create Conversational Chain ===\n",
    "chatbot = ConversationalRetrievalChain.from_llm(\n",
    "    llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.3),\n",
    "    retriever = retriever,\n",
    "    return_source_documents = False\n",
    ")\n",
    "\n",
    "# === Initialize Chat History ===\n",
    "chat_history = [(SUPERPROMPT, \"I'm ready to help with anything about Detective Conan!\")]\n",
    "\n",
    "# === Start Chat Loop ===\n",
    "print(\"Detective Conan Chatbot â€” Start chatting! (type 'quit' to stop)\\n\")\n",
    "while True:\n",
    "    user_input = input(\"You: \").strip()\n",
    "    if user_input.lower() in {\"quit\", \"exit\"}:\n",
    "        print(\"Goodbye, Detective!\")\n",
    "        break\n",
    "\n",
    "    result = chatbot({\"question\": user_input, \"chat_history\": chat_history})\n",
    "    response = result[\"answer\"]\n",
    "    chat_history.append((user_input, response))\n",
    "    print(\"User:\", user_input, flush = True)\n",
    "    print(\"Bot:\", response, flush = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
