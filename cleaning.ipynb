{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "041723f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.3.26-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting langchain-core<1.0.0,>=0.3.66 (from langchain)\n",
      "  Downloading langchain_core-0.3.68-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.8 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting langsmith>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.4.4-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic<3.0.0,>=2.7.4 (from langchain)\n",
      "  Downloading pydantic-2.11.7-py3-none-any.whl.metadata (67 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Downloading sqlalchemy-2.0.41-cp311-cp311-macosx_10_9_x86_64.whl.metadata (9.6 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/pacharaguy/anaconda3/envs/FINER_ABSA/lib/python3.11/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/pacharaguy/anaconda3/envs/FINER_ABSA/lib/python3.11/site-packages (from langchain) (6.0.2)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-core<1.0.0,>=0.3.66->langchain)\n",
      "  Downloading tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<1.0.0,>=0.3.66->langchain)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/pacharaguy/anaconda3/envs/FINER_ABSA/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/pacharaguy/anaconda3/envs/FINER_ABSA/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (4.12.2)\n",
      "Collecting httpx<1,>=0.23.0 (from langsmith>=0.1.17->langchain)\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith>=0.1.17->langchain)\n",
      "  Downloading orjson-3.10.18-cp311-cp311-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl.metadata (41 kB)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith>=0.1.17->langchain)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting zstandard<0.24.0,>=0.23.0 (from langsmith>=0.1.17->langchain)\n",
      "  Downloading zstandard-0.23.0-cp311-cp311-macosx_10_9_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Downloading pydantic_core-2.33.2-cp311-cp311-macosx_10_12_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Downloading typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/pacharaguy/anaconda3/envs/FINER_ABSA/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/pacharaguy/anaconda3/envs/FINER_ABSA/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/pacharaguy/anaconda3/envs/FINER_ABSA/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/pacharaguy/anaconda3/envs/FINER_ABSA/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
      "Collecting greenlet>=1 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Downloading greenlet-3.2.3-cp311-cp311-macosx_11_0_universal2.whl.metadata (4.1 kB)\n",
      "Collecting anyio (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain)\n",
      "  Downloading anyio-4.9.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain)\n",
      "  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain)\n",
      "  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain)\n",
      "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting sniffio>=1.1 (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain)\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Downloading langchain-0.3.26-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_core-0.3.68-py3-none-any.whl (441 kB)\n",
      "Downloading langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\n",
      "Downloading langsmith-0.4.4-py3-none-any.whl (367 kB)\n",
      "Downloading pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
      "Downloading pydantic_core-2.33.2-cp311-cp311-macosx_10_12_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading sqlalchemy-2.0.41-cp311-cp311-macosx_10_9_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading greenlet-3.2.3-cp311-cp311-macosx_11_0_universal2.whl (270 kB)\n",
      "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading orjson-3.10.18-cp311-cp311-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl (248 kB)\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Downloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Downloading zstandard-0.23.0-cp311-cp311-macosx_10_9_x86_64.whl (788 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m788.7/788.7 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading anyio-4.9.0-py3-none-any.whl (100 kB)\n",
      "Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: zstandard, typing-inspection, tenacity, sniffio, pydantic-core, orjson, jsonpointer, h11, greenlet, annotated-types, SQLAlchemy, requests-toolbelt, pydantic, jsonpatch, httpcore, anyio, httpx, langsmith, langchain-core, langchain-text-splitters, langchain\n",
      "Successfully installed SQLAlchemy-2.0.41 annotated-types-0.7.0 anyio-4.9.0 greenlet-3.2.3 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.3.26 langchain-core-0.3.68 langchain-text-splitters-0.3.8 langsmith-0.4.4 orjson-3.10.18 pydantic-2.11.7 pydantic-core-2.33.2 requests-toolbelt-1.0.0 sniffio-1.3.1 tenacity-9.1.2 typing-inspection-0.4.1 zstandard-0.23.0\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b96b5f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import json\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e2592489",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_chunks_from_json(json_data, source_path):\n",
    "    title = json_data.get(\"title\", \"Unknown Title\")\n",
    "    infobox = json_data.get(\"infobox\", {})\n",
    "    sections = json_data.get(\"sections\", {})\n",
    "\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "    all_chunks = []\n",
    "\n",
    "    infobox_text = \"\"\n",
    "    for key, value in infobox.items():\n",
    "        infobox_text += f\"{key.strip()} {value.strip()}\\n\"\n",
    "    if infobox_text.strip():\n",
    "        for chunk in splitter.split_text(infobox_text):\n",
    "            all_chunks.append({\n",
    "                \"text\": chunk,\n",
    "                \"metadata\": {\n",
    "                    \"source\": source_path,\n",
    "                    \"title\": title,\n",
    "                    \"section\": \"infobox\"\n",
    "                }\n",
    "            })\n",
    "\n",
    "    for section_name, content in sections.items():\n",
    "        if content and content.strip():\n",
    "            section_chunks = splitter.split_text(f\"{section_name}:\\n{content.strip()}\")\n",
    "            for chunk in section_chunks:\n",
    "                all_chunks.append({\n",
    "                    \"text\": chunk,\n",
    "                    \"metadata\": {\n",
    "                        \"source\": source_path,\n",
    "                        \"title\": title,\n",
    "                        \"section\": section_name\n",
    "                    }\n",
    "                })\n",
    "\n",
    "    return all_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ae298bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_json_folder(folder_path):\n",
    "    all_chunks = []\n",
    "    for file in Path(folder_path).rglob(\"*.json\"):\n",
    "        with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "            source_path = str(file.relative_to(folder_path))\n",
    "            chunks = extract_chunks_from_json(data, source_path=source_path)\n",
    "            all_chunks.extend(chunks)\n",
    "    return all_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "04b3a691",
   "metadata": {},
   "outputs": [],
   "source": [
    "anime_chunks = process_json_folder(\"Case_Closed_Files/Anime\")\n",
    "character_chunks = process_json_folder(\"Case_Closed_Files/Characters\")\n",
    "gadget_chunks = process_json_folder(\"Case_Closed_Files/Gadgets\")\n",
    "gen_chunks = process_json_folder(\"Case_Closed_Files/General\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ffbfae23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Total Anime Chunks: 26359\n",
      "\n",
      "--- Chunk 1 ---\n",
      "Title: The 14th Round of the Matsue Tamatsukuri Linked Verse Contest\n",
      "Japanese title: 松江玉造連句14番勝負  (Matsue Tamatsukuri Renku Jūyonban Shōbu)\n",
      "Original airdate: October 29, 2001 (Part 1)  November 5, 2001 (Part 2)\n",
      "Broadcast rating: 19.5%  18.6%\n",
      "Filler case: #89\n",
      "Season: 6\n",
      "Manga source: TV Original\n",
      "Cast: Conan Edogawa  Ran Mouri  Kogoro Mouri  Shinichi Kudo\n",
      "Case solved by: Kogoro Mouri (via Conan)\n",
      "Next Conan's Hint: Japanese maple (Part 1)  Hokku (Part 2)\n",
      "Director: Yasuichiro Yamamoto\n",
      "Metadata: {'source': 'The_14th_Round_of_the_Matsue_Tamatsukuri_Linked_Verse_Contest_(Part_1).json', 'title': 'The 14th Round of the Matsue Tamatsukuri Linked Verse Contest (Part 1)', 'section': 'infobox'}\n",
      "\n",
      "--- Chunk 2 ---\n",
      "Director: Yasuichiro Yamamoto\n",
      "Screenplay: Kazunari Kouchi\n",
      "Storyboard: 255: Yasuichiro Yamamoto  256: Murazou Sugisawa\n",
      "Episode director: 255: Mashu Ito  256: Nana Harada\n",
      "Animation director: 255: Hirobi Muranaka  256: Atsushi Aono\n",
      "Character design: Masatomo Sudo  Junko Yamanaka and Kumiko Shishido (design works)\n",
      "Voice Cast: Voice Cast:\n",
      "Metadata: {'source': 'The_14th_Round_of_the_Matsue_Tamatsukuri_Linked_Verse_Contest_(Part_1).json', 'title': 'The 14th Round of the Matsue Tamatsukuri Linked Verse Contest (Part 1)', 'section': 'infobox'}\n",
      "\n",
      "--- Chunk 3 ---\n",
      "Minami Takayama as Conan Edogawa, Next Conan's Hint (Part 2)  Kappei Yamaguchi as Shinichi Kudo, Next Conan's Hint (Part 1)  Wakana Yamazaki as Ran Mouri, Next Conan's Hint (Part 2)  Akira Kamiya as Kogoro Mouri  Chiharu Suzuka as Reiko Ando  Masahiko Tanaka as Takumi Yagisawa  Koji Yusa as Ryosuke Shiina  Konami Yoshida as Mizuki Kawaguchi  Masashi Hirose as Kozo Ushikubo  Junichi Sugawara as Hisatoshi Tomonaga  Fumiko Miyashita as Receptionist  Hidenari Ugaki as Detective Yasugi  Kenta Miyake\n",
      "Metadata: {'source': 'The_14th_Round_of_the_Matsue_Tamatsukuri_Linked_Verse_Contest_(Part_1).json', 'title': 'The 14th Round of the Matsue Tamatsukuri Linked Verse Contest (Part 1)', 'section': 'infobox'}\n",
      "\n",
      "--- Chunk 4 ---\n",
      "Hidenari Ugaki as Detective Yasugi  Kenta Miyake as Detective Tsubaki  Isshin Chiba as Detective Hirose\n",
      "Metadata: {'source': 'The_14th_Round_of_the_Matsue_Tamatsukuri_Linked_Verse_Contest_(Part_1).json', 'title': 'The 14th Round of the Matsue Tamatsukuri Linked Verse Contest (Part 1)', 'section': 'infobox'}\n",
      "\n",
      "--- Chunk 5 ---\n",
      "Opening song: destiny\n",
      "Closing song: Aoi Aoi Kono Hoshi ni\n",
      "Metadata: {'source': 'The_14th_Round_of_the_Matsue_Tamatsukuri_Linked_Verse_Contest_(Part_1).json', 'title': 'The 14th Round of the Matsue Tamatsukuri Linked Verse Contest (Part 1)', 'section': 'infobox'}\n"
     ]
    }
   ],
   "source": [
    "print(f\"✅ Total Anime Chunks: {len(anime_chunks)}\")\n",
    "\n",
    "for i, chunk in enumerate(anime_chunks[:5]):\n",
    "    print(f\"\\n--- Chunk {i+1} ---\")\n",
    "    print(chunk[\"text\"])\n",
    "    print(\"Metadata:\", chunk[\"metadata\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2abe1bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"anime_chunks.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(anime_chunks, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "with open(\"character_chunks.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(character_chunks, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "with open(\"gadget_chunks.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(gadget_chunks, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "with open(\"general_chunks.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(gen_chunks, f, ensure_ascii=False, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433e0b8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (FINER_ABSA)",
   "language": "python",
   "name": "finer_absa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
